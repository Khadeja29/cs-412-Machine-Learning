{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KhadejaIqbal_26242_ML202102_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khadeja29/cs-412-Machine-Learning/blob/main/KhadejaIqbal_26242_ML202102_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsPftUCDDurU"
      },
      "source": [
        "# CS 412 Machine Learning 2020 \n",
        "\n",
        "# Assignment 3\n",
        "\n",
        "100 pts\n",
        "\n",
        "## Goal \n",
        "\n",
        "The goal of this assignment \n",
        "\n",
        "*  Introduction to working with text data\n",
        "*  Gain experience with the Scikit-Learn library\n",
        "*  Gain experience with Naive Bayes and Logistic Regression\n",
        "\n",
        "## Dataset\n",
        "\n",
        "**20 Newsgroup Dataset** is a collection 18846 documents which are about 20 different topics.\n",
        "\n",
        "\n",
        "## Task\n",
        "Build naive bayes and logistic regression classifiers with the scikit-learn library function to **classify** the documents about their content topic.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Follow the instructions at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNnWi0hUEE_P"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JritpHX7EKdr"
      },
      "source": [
        "# 2) Load Dataset\n",
        "\n",
        "The 20 Newsgroup Dataset exist on Scikit-Learn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me2JuqB9EN3U"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zOI7YAhE2x3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440d6b02-87c9-415c-c089-bffc21db4e12"
      },
      "source": [
        "train_batch = fetch_20newsgroups(subset='train')\n",
        "test_batch = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkSAOk1aKUzl",
        "outputId": "22160d3b-7eb5-4078-e521-6277c17cca3e"
      },
      "source": [
        "# target groups you will be dealing with\n",
        "target_groups = train_batch.target_names\n",
        "target_groups"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEY5XoYmFVTr"
      },
      "source": [
        "# creating training and test sets\n",
        "train_x =  train_batch[\"data\"]\n",
        "train_y =  train_batch[\"target\"]\n",
        "test_x  =  test_batch[\"data\"]\n",
        "test_y  =  test_batch[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aiFqFY-Ftkc",
        "outputId": "ad478c37-7a58-4a99-af9d-ada70e82ecda"
      },
      "source": [
        "print(train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa_vTE97NsSL",
        "outputId": "974dae25-d9ef-40c1-edbb-82f51dd9ca5a"
      },
      "source": [
        "print(target_groups[train_y[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rec.autos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV4AaTk8JSPg"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZdKd6oAJWrj"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aukUdxk3JXft"
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1oq7z0wJXdj"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldItHamFJwcO"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YL6H0AQHwZl"
      },
      "source": [
        "# You will use this function to preprocess your data. If you would like to add another preprocessing step in the function, please add it and mention about it in your report.\n",
        "def preprocess(text):\n",
        "  text = re.sub(\"[\\w\\d._]+@[^\\s]+|[^\\s]+\\.[^\\s]+|[^\\s]+-[^\\s]+|\\d+|[^\\w\\s]\",\"\",text.lower().strip())\n",
        "  text = ' '.join([stemmer.stem(word) for word in re.findall(\"\\w+\",text) if word not in stop_words])\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL-jPAXPJffh"
      },
      "source": [
        "# Apply <preprocess> function on the training and test set \n",
        "preprocessed_train_x = [preprocess(sample) for sample in train_x]\n",
        "preprocessed_test_x  = [preprocess(sample) for sample in test_x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOFFQwnUOCCY"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yoKTkRCOFQh"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXJGT2HpNY8_"
      },
      "source": [
        "## Tune Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA5QFz37BoBc"
      },
      "source": [
        "# Create a CountVectorizer for NB with:\n",
        "#     min_df = 50\n",
        "#     max_df = 3000\n",
        "#     stop_words = stop_words\n",
        "\n",
        "vectorizer = CountVectorizer(min_df = 50,max_df = 3000,stop_words = stop_words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS5WNNEhBxiZ"
      },
      "source": [
        "# Vectorize your training and test set\n",
        "train_x_nb = vectorizer.fit_transform(preprocessed_train_x)\n",
        "test_x_nb = vectorizer.transform(preprocessed_test_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVdPwcrsNymU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44c922e-835a-46fd-e67f-83e9f4cdf791"
      },
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "#Initiate the NB model with required components.\n",
        "model =MultinomialNB()\n",
        "\n",
        "#Set the hyperparameter space that will be scanned:\n",
        "#   alpha = (0.1,0.5,1.0,5.0)\n",
        "mnb_pipeline = Pipeline([\n",
        "                         \n",
        "                         (\"clf\", model)\n",
        "])\n",
        "hyperparameters = dict(\n",
        "    clf__alpha = (0.1,0.5,1.0,5.0),\n",
        ")\n",
        "#Let the GridSearchCV scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option.\n",
        "#   cv = 3\n",
        "#   scoring = \"accuracy\"\n",
        "mnb_grid_search = GridSearchCV(mnb_pipeline,hyperparameters,cv=3,scoring=\"accuracy\",n_jobs=-1)\n",
        "mnb_grid_search.fit(train_x_nb,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('clf',\n",
              "                                        MultinomialNB(alpha=1.0,\n",
              "                                                      class_prior=None,\n",
              "                                                      fit_prior=True))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.1, 0.5, 1.0, 5.0)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4xyqjD1N5Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba344a6-5009-4c30-e4d1-c61e17f60054"
      },
      "source": [
        "# show the best score\n",
        "mnb_grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD888YxgO9d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d6fa90-37bc-4825-da4a-4eb94fef25c3"
      },
      "source": [
        "# show the best parameter\n",
        "mnb_grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8212835269890522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJu_rA56W5jn"
      },
      "source": [
        "### Evaluate The Best Model for NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTTHdeA4O_kd"
      },
      "source": [
        "#Create your NB model with the best parameter set.\n",
        "\n",
        "model_nb_final= MultinomialNB(alpha=0.5)\n",
        "#Fit your model on training set.\n",
        "model_nb_final = model_nb_final.fit(train_x_nb,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unaw09TcXDGO"
      },
      "source": [
        "# Make predictions on test set\n",
        "predictions =model_nb_final.predict(test_x_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIkAMwHKXEym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15d7aba-cce9-4228-e726-f4c358cc26b3"
      },
      "source": [
        "# Show your accuracy on test set\n",
        "accuracy_score(test_y,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7555762081784386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJX62dPOXPdH"
      },
      "source": [
        "## Tune Logistic Regresion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1JQhjs3Cf2k"
      },
      "source": [
        "# Create a CountVectorizer for LR with:\n",
        "#     min_df = 50\n",
        "#     max_df = 3000\n",
        "#     stop_words = stop_words\n",
        "\n",
        "vectorizer2 = CountVectorizer( min_df = 50,max_df = 3000,stop_words = stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTa3qQPCC0ts"
      },
      "source": [
        "# Vectorizer your training and test set\n",
        "train_x_lr = vectorizer2.fit_transform(preprocessed_train_x)\n",
        "test_x_lr = vectorizer2.transform(preprocessed_test_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv2aolaqXF5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658468a7-867a-4d7c-ad97-ed0e71c6e9db"
      },
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "#Initiate the LR model:\n",
        "#   max_iter=2000\n",
        "model_lr= LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Set the hyperparameter space that will be scanned:\n",
        "#     C = (0.001,0.01,0.1,1)     \n",
        "mnb_pipeline = Pipeline([\n",
        "                         \n",
        "                         (\"clf\", model_lr)\n",
        "])\n",
        "hyperparameters = dict(\n",
        "    clf__C = (0.001,0.01,0.1,1),\n",
        ")\n",
        "\n",
        "#Let the GridSearchCV scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option.\n",
        "#   cv = 3\n",
        "#   scoring = \"accuracy\"\n",
        "\n",
        "mnb_grid_search = GridSearchCV(mnb_pipeline,hyperparameters,cv=3,scoring=\"accuracy\",n_jobs=-1)\n",
        "mnb_grid_search.fit(train_x_lr,train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('clf',\n",
              "                                        LogisticRegression(C=1.0,\n",
              "                                                           class_weight=None,\n",
              "                                                           dual=False,\n",
              "                                                           fit_intercept=True,\n",
              "                                                           intercept_scaling=1,\n",
              "                                                           l1_ratio=None,\n",
              "                                                           max_iter=2000,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__C': (0.001, 0.01, 0.1, 1)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhToPngFlsRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b83f08-121b-4b5c-f850-49f0675d63a2"
      },
      "source": [
        "# show the best score\n",
        "mnb_grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8338344038554356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKQh_pyJl7cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13f87b5-37bf-4501-f0b8-748e39fa4662"
      },
      "source": [
        "# show the best parameter\n",
        "mnb_grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__C': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6n8TCfTbK8N"
      },
      "source": [
        "### Evaluate The Best Model for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIEOi8FEYcC8"
      },
      "source": [
        "#Create your LR model with the best parameter set.\n",
        "model_lr_final =LogisticRegression(max_iter=2000, C=0.1)\n",
        "#Fit your model on training set.\n",
        "model_lr_final =model_lr_final.fit(train_x_lr,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u1ah0awbY4t"
      },
      "source": [
        "# Make predictions on test set\n",
        "pred= model_lr_final.predict(test_x_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vH2DKHhbrPa"
      },
      "source": [
        "# Show your accuracy on test set\n",
        "accuracy_score(test_y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exoff4yjb7uI"
      },
      "source": [
        "# Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m38zVUcMUE-Y"
      },
      "source": [
        "lr_df = pd.DataFrame(columns=target_groups)\n",
        "nb_df = pd.DataFrame(columns=target_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLctLNhJoki"
      },
      "source": [
        "# Find the each category's most important top 3 features (words) for LR model and show with a dataframe\n",
        "def feature_impo(model,target_groups,vectorizer):\n",
        "    feature= np.asarray(vectorizer.get_feature_names())\n",
        "    for i, t in enumerate(target_groups):\n",
        "      lr_df[t]= feature[np.argsort(model.coef_[i])[-3:]][::-1] \n",
        "\n",
        "feature_impo(model_lr_final,target_groups,vectorizer2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyrfNfYrKOlg"
      },
      "source": [
        "# It should look like this:\n",
        "lr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H1cA8uAK42r"
      },
      "source": [
        "# Find the each category's most important top 3 features (words) for NB model and show with a dataframe\n",
        "def feature_impo(model,target_groups,vectorizer):\n",
        "    feature= np.asarray(vectorizer.get_feature_names())\n",
        "    for i, t in enumerate(target_groups):\n",
        "      nb_df[t]= feature[np.argsort(model.feature_log_prob_[i])[-3:]][::-1] \n",
        "\n",
        "feature_impo(model_nb_final,target_groups,vectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtwfzWhgLhF4"
      },
      "source": [
        "# It should look like this:\n",
        "nb_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPWqanx2QgmX"
      },
      "source": [
        "# **Notebook & Report**\n",
        "\n",
        "Notebook: We may just look at your notebook results; so make sure each cell is run and outputs are there.\n",
        "\n",
        "Report: Write an at most 1/2 page summary of your approach to this problem at the end of your notebook; this should be like an abstract of a paper or the executive summary.\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "( Include the problem definition: 1-2 lines )\n",
        "\n",
        "(Talk about any preprocessing you did, explain your reasoning)\n",
        "\n",
        "(Talk about train/test sets, size and how split)\n",
        "\n",
        "(State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\")\n",
        "\n",
        "(Comment on feature importances of models)\n",
        "\n",
        "(Comment on anything that you deem important/interesting)\n",
        "\n",
        "\n",
        "You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkzSQwJRHFE"
      },
      "source": [
        "# **REPORT**\n",
        "\n",
        "### **PROBLEM DEFINITION**\n",
        "The aim of this project is to build naive bayes and logistic regression classifier models to **classify** the documents according to their textual content.\n",
        "\n",
        "### **TEXT CLEANING & PREPROCESSING**\n",
        "\n",
        "To improve the performace of the model,avoid noise and overfitting it is a good practice to clean or preprocess text data.\n",
        "We apply the following preprocessing to the data:\n",
        "\n",
        "1. **Lower case:** The word \"Plant\", \"plant\" and \"PLANT\" are actually the same word amd converting them all to one format i.e lowercase will be more efficient and will prevent the model to overfit data for the same word.\n",
        "2. **Stopwords:** Stop words like \"is\", \"this\" etc are removed because they add noise and have low information that they provide to the model.Stopwords do not add anything to the meaning of a sentence and can removed without causing probelms while training the model. \n",
        "3. **SnowballStemmer**: Stemming gets the root form of a word removing for example affixes like -ed, -ize, -de, -s etc added to the end of words. The stem words are created by removing the prefix or suffix of a word.\n",
        "We need to convert the words firstly into tokens if they are not already tokens and then we covert themt to their root forms.This is also done to prevent the model from overlearning./overfitting the same word that is used in difeerent forms only.\n",
        "\n",
        "4. **Numbers,Special Characters,Punctuation**: These do not provide any additional information to a text for classigication.\n",
        "\n",
        "### **TRAIN AND TEST DATA SPLITING**\n",
        "We import two data sets already that are split into two train and test sets. We sepatate the data and target for both train and test data and apply preprocessing to the data of both train and test. \n",
        "\n",
        "### **PERFORMANCE AND RESULTS**\n",
        "\n",
        "We have obtained the best results with the **Naive Bayes classifier** **(parameters= alpha =0.5)** , giving classification accuracy of **75.5%** on test data.\n",
        "  \n",
        "### **FEATURE IMPORTANCE OF MODELS**\n",
        "Feature importance is carried out to find the most frequently occuring features in a topic/caterogry that assist the model in prediciting then topic/categories/targte_group.\n",
        "\n",
        "From the documentation, we can use these attributes of the models:\n",
        "\n",
        "**.feature_log_prob_** or **coef_** to find the probility of a feature(from the vectorizer) observed given a class. For Naiver Bayes we can use either of these of these. \n",
        "\n",
        "While from the documnetation of Logistic Regression :\n",
        "**coef_** attribute finds the Coefficient of the features in the decision function.\n",
        "\n",
        "In the above both functions `feature_impo` we first used the respective attributes of the models to get an ndarray for all features with their coefficitents.From that list we get the indexes of the 3 most freqently occuring words/features in ascending order wrt to the frequency/probabilty of occurence.To display then in descending ordere we reverse the list.\n",
        "We add these lists under their respective columns.\n",
        "\n",
        "### **OBSERVATIONS**\n",
        "\n",
        "The 3 most important words or features are different for both naive bayes and logistic regression for prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5luVvQnRJr7"
      },
      "source": [
        "# **Submission**\n",
        "You will submit this homework via SUCourse.\n",
        "\n",
        "\n",
        "Please read this document again before submitting it.\n",
        "\n",
        "Please submit your **\"share link\" INLINE in Sucourse submissions.** That is we should be able to click on the link and go there and run (and possibly also modify) your code.\n",
        "\n",
        "For us to be able to modify, in case of errors etc, you should get your \"share link\" as **share with anyone in edit mode** \n",
        "\n",
        "Download the **.ipynb and the .html** file and upload both of them to Sucourse.\n",
        " \n",
        "Please do your assignment individually, do not copy from a friend or the Internet. Plagiarized assignments will receive -100.\n"
      ]
    }
  ]
}